{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clone the repository\n!git clone --branch Colab-installer (link unavailable) 2> /dev/null 1>&2\nprint(\"Cloning Ollama-Companion from git...\")\n\n# Install virtualenv\n!apt-get install virtualenv 2> /dev/null 1>&2\nprint(\"Installing some dependencies, please hold on...\")\n\n# Convert Windows line endings to Unix line endings in the install.sh script\n!sed -i 's/\\r//' /kaggle/working/Ollama-Companion/install.sh 2> /dev/null 1>&2\nprint(\"Converting line endings in install script...\")\n\n# Make the script executable and run it\n!chmod +x /kaggle/working/Ollama-Companion/install.sh 2> /dev/null 1>&2\nprint(\"Running the installation script and compiling Llama.cpp...\")\n!/kaggle/working/Ollama-Companion/install.sh 2> /dev/null 1>&2\n\n# Run the application\n!python3 /kaggle/working/Ollama-Companion/run_app.py\nprint(\"Started all apps run the cell below if you want to restart\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T03:32:28.919114Z","iopub.execute_input":"2024-04-26T03:32:28.920574Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/bin/bash: -c: line 0: syntax error near unexpected token `('\n/bin/bash: -c: line 0: `git clone --branch Colab-installer (link unavailable) 2> /dev/null 1>&2'\nCloning Ollama-Companion from git...\n^C\nInstalling some dependencies, please hold on...\nConverting line endings in install script...\nRunning the installation script and compiling Llama.cpp...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 /kaggle/working/Ollama-Companion/run_app.py","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:32:16.190004Z","iopub.execute_input":"2024-04-26T03:32:16.190644Z","iopub.status.idle":"2024-04-26T03:32:17.290621Z","shell.execute_reply.started":"2024-04-26T03:32:16.190599Z","shell.execute_reply":"2024-04-26T03:32:17.289012Z"},"trusted":true},"execution_count":6,"outputs":[]}]}